<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AKA-Net: A Self-supervised Colonoscopy Colonoscopy Pose Estimation Method with Attentional Keypoints Adjustment Module</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css"> <!-- 引用 CSS 样式 -->
</head>
<body>

    <div class="container">
        <!-- Header Section -->
        <div class="header">
            <h1>AKA-Net: A Self-supervised Colonoscopy Colonoscopy Pose Estimation Method with Attentional Keypoints Adjustment Module</h1>
            <p><em>Anonymous, Senior Member, IEEE</em></p>   
        </div>
        
        <p><em>※ Anonymous. <br>※ Anonymous.<br>※ Anonymous.<br>※ Anonymous.</em></p>

<!-- Resources Section -->
        <div class="content-section">
            <h2 class="section-title">Resources</h2>
            <ul>
                <li><a href="" target="_blank">Download Paper (PDF)</a></li>
                <li><a href="https://tokymin.github.io/aka-net/" target="_blank">Code on GitHub</a></li>
            </ul>
        </div>
        <!-- Video Section -->
        

        

        <!-- Abstract Section -->
        <div class="content-section">
            <h2 class="section-title">Abstract</h2>
            <p>Due to the tortuous and complicated characteristics of the human intestinal tract, effective navigation, including colonoscope localization and environment perception, is significant for both manual and robot-assisted colonoscopy procedures. Accurate pose estimation of the colonoscope is crucial for visual navigation, as self-tracking in vivo is challenging due to the dynamic nature of the colon tissue. However, existing pose estimation methods often suffer from the mislocation in keypoint extraction and visual distortions under colonoscopy scenario. Methods: To address these problems, we propose AKA-Net, a self-supervised network crafted for keypoint extraction in a colonoscopy environment. Specifically, we propose a novel attentional keypoints adjustment (AKA) module, which improves the performance of keypoint extraction by leveraging historical attention residual to efficiently refine the locating of keypoints in the current frame. Additionally, we propose two optimization strategies to address the visual distortion issues in colonoscopic images, which separately suppress motion artifacts in the low-frequency information and illumination discrepancy in the high-frequency information. Results: Our network undergoes training on a dataset collected from a simulated colonoscopy environment powered by the Unity platform, and its effectiveness is subsequently validated through a custom-made colon phantom data acquisition setup. Conclusions: The outcomes demonstrate an Average Trajectory Estimation Error (ATE) of 1.26±0.48mm on the Unity dataset and 1.44±0.49mm on the Phantom dataset, highlighting the potential of our network for application in both manual and robot-assisted colonoscopy procedures.</p>
        </div>

        <!-- Image Row Section -->
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F10.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F2.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>

        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F1.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F3.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F4.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F5.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F6.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F7.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F8.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="container image-row">
            <div class="row">
                <div class="col-md-6 image-container">
                    <img src="images/F9.jpg" class="img-fluid" alt="Second Image">
                </div>
            </div>
        </div>
        <div class="content-section">
            <h2 class="section-title">Results</h2>
            <p>This study addresses the challenges of safe and efficient navigation in automated robotic digestive endoscopy (RDE) within the unstructured and narrow confines of the digestive tract. We proposed a human intervention-based PPO framework by incorporating expert knowledge to address the safety and effectiveness of RDE. Experiments have shown that HI-PPO can safely guide RDE compared to existing RL algorithms, indicating its potential for more practical application. Future work will focus on validating the framework in real environments and exploring additional methods to further enhance its safety and practicality.</p>
            <!-- <div class="container image-row">
                <div class="row">
                    <div class="col-md-6 image-container">
                        <img src="images/F4.jpg" class="img-fluid" id="custom-img" alt="F4.jpg">
                    </div>
                    <div class="col-md-6 image-container">
                        <img src="images/F5.jpg" class="img-fluid" alt="Second Image">
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-6 image-container">
                        <img src="images/F6.jpg" class="img-fluid" alt="Second Image">
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-6 image-container">
                        <img src="images/F7.jpg" class="img-fluid" alt="Second Image">
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-6 image-container">
                        <img src="images/F8.jpg" class="img-fluid" alt="Second Image">
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-6 image-container">
                        <img src="images/F9.jpg" class="img-fluid" alt="Second Image">
                    </div>
                </div>
            </div> -->
       
    </div>

    <!-- Scripts -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.6.0/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>


    <!-- Footer Section -->
    <footer>
        <p>© 2024 SIAT-MedRobot</p>
    </footer>

</body>
</html>
